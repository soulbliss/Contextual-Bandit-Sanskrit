{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdatafromsite(line, linetype):  # Scrapping data from site\n",
    "    inputline = line\n",
    "    inputtype = linetype\n",
    "    problem = []\n",
    "    pbwords = []\n",
    "    s_type = {}\n",
    "    s_type['WX'] = 'WX'\n",
    "    s_type['SLP'] = 'SL'\n",
    "    s_type['Velthuis'] = 'VH'\n",
    "    s_type['KH'] = 'KH'\n",
    "\n",
    "    s_d = inputline\n",
    "\n",
    "    s_c = s_d.replace(\" \", \"+\")\n",
    "    # for utilising the sanskrit heritage app, the url has been specified\n",
    "    urlname = (\"http://sanskrit.inria.fr/cgi-bin/SKT/sktgraph?lex=SH&st=f&us=f&cp=t&text=\" +\n",
    "               s_c + \"&t=\" + s_type[inputtype] + \"&topic=&mode=g&corpmode=&corpdir=&sentno=\")\n",
    "\n",
    "    print(urlname)\n",
    "    #time.sleep(2)\n",
    "    page = requests.get(urlname)\n",
    "    # parsing using beautifulsoup\n",
    "    soup = bs(page.text, 'html.parser')\n",
    "    table = soup.table\n",
    "    tablebody = table.find('table', {'class': 'center'})\n",
    "    t = pd.DataFrame(\n",
    "        columns=['id', 'level', 'color_class', 'position', 'chunk_no', 'word', 'lemma', 'pre_verb', 'morph', 'colspan',\n",
    "                 'wordlenth', 'aux_inf'])\n",
    "\n",
    "    i = 0\n",
    "    id_ = 0\n",
    "    if not (tablebody):  #### wronginputs\n",
    "        print('no table body of given inputline')\n",
    "\n",
    "    # for valid entries corresponding to Wordsinsentence\n",
    "    for child in tablebody.children:\n",
    "        if (child.name == 'tr'):\n",
    "            if i < 1:\n",
    "                linechar = []\n",
    "                c = 0\n",
    "                for char in child.children:\n",
    "                    linechar.append(char.string)\n",
    "                    c += 1\n",
    "                i += 1\n",
    "                line_header = \"\".join(linechar)\n",
    "                linechunks = line_header.split(\"\\xa0\")\n",
    "                continue\n",
    "            position_ = 0\n",
    "            j = 0\n",
    "            for wordtable in child.children:\n",
    "                c = 0\n",
    "                for ch in linechar[0:position_]:\n",
    "                    if (re.match('\\xa0', ch)):  # or (re.match('_',ch))\n",
    "                        c += 1\n",
    "                    # if the contents exist in wordtable\n",
    "                    # following assignings are carried out.\n",
    "                if (wordtable.contents):\n",
    "                    color_ = wordtable.table.get('class')[0]\n",
    "                    colspan_ = wordtable.get('colspan')\n",
    "                    word_ = wordtable.table.tr.td.string\n",
    "                    onclickdatas_ = wordtable.table.tr.td.get('onclick')\n",
    "                    for onclickdata_ in onclickdatas_.split(\"<br>\"):  # required splits carried out at positions stated\n",
    "                        morphslist_ = re.findall(r'{ (.*?) }', onclickdata_)  # .split(' | ')\n",
    "                        ldata = str(re.search(r'{.*?}\\[(.*)\\]', onclickdata_).group(1))\n",
    "                        ldata = str(re.sub(r'</?a.*?>|</?i>', \"\", ldata))\n",
    "\n",
    "                        lemmadata = ldata.split(\" \")\n",
    "                        if len(lemmadata) > 1:\n",
    "                            auxi_ = \" \".join(lemmadata[1:])\n",
    "                        else:\n",
    "                            auxi_ = \"\"\n",
    "                        lemmas_ = \"\".join(lemmadata[0])\n",
    "                        lemmalists_ = lemmas_.split(\"-\")\n",
    "                        if (len(lemmalists_) > 1):\n",
    "                            preverb_ = \",\".join(lemmalists_[0:(len(lemmalists_) - 1)])\n",
    "                            lemmalist_ = \"\".join(lemmalists_[-1:]).split(\"_\")\n",
    "                        else:\n",
    "                            preverb_ = \"\"\n",
    "                            lemmalist_ = \"\".join(lemmalists_[0]).split(\"_\")\n",
    "                        if (len(lemmalist_) > 1):\n",
    "                            auxi_ = auxi_ + \" sence of lemma = \" + \"\".join(lemmalist_[1:(len(lemmalist_))])\n",
    "                            lemma_ = \"\".join(lemmalist_[0])\n",
    "                        else:\n",
    "                            lemma_ = \"\".join(lemmalist_[0])\n",
    "                        morphs_ = str(morphslist_[0])\n",
    "                        for morph_ in morphs_.split(\" | \"):\n",
    "                            t.loc[id_] = [id_, i, color_, position_, c + 1, word_, lemma_, preverb_, morph_,\n",
    "                                          int(colspan_), len(word_), auxi_]\n",
    "                            if (re.match(r'grey_back', color_)):\n",
    "                                if not (word_ == 'pop'):\n",
    "                                    problem.append(id_)  # filling entries to problem list\n",
    "                                else:\n",
    "                                    id_ = id_ - 1\n",
    "                            id_ += 1\n",
    "\n",
    "                    position_ += int(colspan_)\n",
    "                else:\n",
    "                    position_ += 1\n",
    "            i = i + 1\n",
    "            dict_ = {'t':t,'line_header':line_header}\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "# Double characters mapping to single characters\n",
    "_dbl = dict({\n",
    "    'ai' : 'E',\n",
    "    'au' : 'O',\n",
    "    'kh' : 'K',\n",
    "    'gh' : 'G',\n",
    "    'ch' : 'C',\n",
    "    'jh' : 'J',\n",
    "    'ṭh' : 'W',\n",
    "    'ḍh' : 'Q',\n",
    "    'th' : 'T',\n",
    "    'dh' : 'D',\n",
    "    'ph' : 'P',\n",
    "    'bh' : 'B'})\n",
    "\n",
    "# One to one mapping\n",
    "_oth = dict({\n",
    "    'ā' : 'A',\n",
    "    'ī' : 'I',\n",
    "    'ū' : 'U',\n",
    "    'ṛ' : 'f',\n",
    "    'ṝ' : 'F',\n",
    "    'ḷ' : 'x',\n",
    "    'ḹ' : 'X',\n",
    "    'ṃ' : 'M',\n",
    "    'ḥ' : 'H',\n",
    "    'ṁ' : '~',\n",
    "    'ṅ' : 'N',\n",
    "    'ñ' : 'Y',\n",
    "    'ṭ' : 'w',\n",
    "    'ḍ' : 'q',\n",
    "    'ṇ' : 'R',\n",
    "    'ś' : 'S',\n",
    "    'ṣ' : 'z'})\n",
    "\n",
    "def iast2slp(src):\n",
    "    '''\n",
    "    Converts International Alphabet for Sanskrit Transliteration (IAST) scheme to\n",
    "    Sanskrit Library Phonetic Basic notation\n",
    "    '''\n",
    "    tgt = ''\n",
    "    inc = 0\n",
    "    while inc < len(src):\n",
    "        now = src[inc]\n",
    "        nxt = src[inc+1] if inc < len(src) - 1 else ''\n",
    "        if now + nxt in _dbl:\n",
    "            tgt += _dbl[now + nxt]\n",
    "            inc += 1\n",
    "        elif now in _oth:\n",
    "            tgt += _oth[now]\n",
    "        else:\n",
    "            tgt += now\n",
    "        inc += 1\n",
    "    return tgt\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://sanskrit.inria.fr/cgi-bin/SKT/sktgraph?lex=SH&st=f&us=f&cp=t&text=AcaraRIyam&t=SL&topic=&mode=g&corpmode=&corpdir=&sentno=\n"
     ]
    }
   ],
   "source": [
    "data_pack = getdatafromsite('AcaraRIyam', 'SLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>level</th>\n",
       "      <th>color_class</th>\n",
       "      <th>position</th>\n",
       "      <th>chunk_no</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pre_verb</th>\n",
       "      <th>morph</th>\n",
       "      <th>colspan</th>\n",
       "      <th>wordlenth</th>\n",
       "      <th>aux_inf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>deep_sky_back</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ācaraṇīyam</td>\n",
       "      <td>caraṇīya</td>\n",
       "      <td>ā</td>\n",
       "      <td>acc. sg. n.</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{ pfp. [2] }[ā-car]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>deep_sky_back</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ācaraṇīyam</td>\n",
       "      <td>caraṇīya</td>\n",
       "      <td>ā</td>\n",
       "      <td>nom. sg. n.</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{ pfp. [2] }[ā-car]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>deep_sky_back</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ācaraṇīyam</td>\n",
       "      <td>caraṇīya</td>\n",
       "      <td>ā</td>\n",
       "      <td>acc. sg. m.</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{ pfp. [2] }[ā-car]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id level    color_class position chunk_no        word     lemma pre_verb  \\\n",
       "0  0     1  deep_sky_back        0        1  ācaraṇīyam  caraṇīya        ā   \n",
       "1  1     1  deep_sky_back        0        1  ācaraṇīyam  caraṇīya        ā   \n",
       "2  2     1  deep_sky_back        0        1  ācaraṇīyam  caraṇīya        ā   \n",
       "\n",
       "         morph colspan wordlenth              aux_inf  \n",
       "0  acc. sg. n.      10        10  { pfp. [2] }[ā-car]  \n",
       "1  nom. sg. n.      10        10  { pfp. [2] }[ā-car]  \n",
       "2  acc. sg. m.      10        10  { pfp. [2] }[ā-car]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pack['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    caraṇīya\n",
       "1    caraṇīya\n",
       "2    caraṇīya\n",
       "Name: lemma, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pack['t']['lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
