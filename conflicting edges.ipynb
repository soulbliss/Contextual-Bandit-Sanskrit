{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pickle\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are representative 6 files, \n",
    "which have correct ground truth ids, however **have conflicting edges between them**.\n",
    "\n",
    "\n",
    "Of 4k sentences,\n",
    "\n",
    "177 fail complete graph test.\n",
    "\n",
    "Of that these issues comprise 74% of such cases (~130 sentences).\n",
    "\n",
    "29088\n",
    "<br>\n",
    "122173\n",
    "<br>\n",
    "190932\n",
    "<br>\n",
    "45474\n",
    "<br>\n",
    "74231\n",
    "<br>\n",
    "27284\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just change the filenames\n",
    "\n",
    "graphml_file = '29088.graphml'\n",
    "pickle_file = '29088.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "PICKLE_DCS_FILE_NAME = os.path.join(BASE_DIR,'data','conflict',pickle_file)\n",
    "GRAPHML_FILE_NAME = os.path.join(BASE_DIR,'data','conflict',graphml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining class for pickle file \n",
    "\n",
    "class DCS:\n",
    "    def __init__(self, sent_id, sentence):\n",
    "        self.sent_id = sent_id\n",
    "        self.sentence = sentence\n",
    "        self.dcs_chunks = []\n",
    "        self.lemmas = []\n",
    "        self.cng = []\n",
    "\n",
    "dcs_class_params = ['sentence id', 'sentence ', 'chunks', 'lemmas', 'morph class']        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Double characters mapping to single characters\n",
    "_dbl = dict({\n",
    "    'ai' : 'E',\n",
    "    'au' : 'O',\n",
    "    'kh' : 'K',\n",
    "    'gh' : 'G',\n",
    "    'ch' : 'C',\n",
    "    'jh' : 'J',\n",
    "    'ṭh' : 'W',\n",
    "    'ḍh' : 'Q',\n",
    "    'th' : 'T',\n",
    "    'dh' : 'D',\n",
    "    'ph' : 'P',\n",
    "    'bh' : 'B'})\n",
    "\n",
    "# One to one mapping\n",
    "_oth = dict({\n",
    "    'ā' : 'A',\n",
    "    'ī' : 'I',\n",
    "    'ū' : 'U',\n",
    "    'ṛ' : 'f',\n",
    "    'ṝ' : 'F',\n",
    "    'ḷ' : 'x',\n",
    "    'ḹ' : 'X',\n",
    "    'ṃ' : 'M',\n",
    "    'ḥ' : 'H',\n",
    "    'ṁ' : '~',\n",
    "    'ṅ' : 'N',\n",
    "    'ñ' : 'Y',\n",
    "    'ṭ' : 'w',\n",
    "    'ḍ' : 'q',\n",
    "    'ṇ' : 'R',\n",
    "    'ś' : 'S',\n",
    "    'ṣ' : 'z'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##IAST to SLP1 transliteration\n",
    "\n",
    "\n",
    "def iast2slp(src):\n",
    "    '''\n",
    "    Converts International Alphabet for Sanskrit Transliteration (IAST) scheme to\n",
    "    Sanskrit Library Phonetic Basic notation\n",
    "    '''\n",
    "    tgt = ''\n",
    "    inc = 0\n",
    "    while inc < len(src):\n",
    "        now = src[inc]\n",
    "        nxt = src[inc+1] if inc < len(src) - 1 else ''\n",
    "        if now + nxt in _dbl:\n",
    "            tgt += _dbl[now + nxt]\n",
    "            inc += 1\n",
    "        elif now in _oth:\n",
    "            tgt += _oth[now]\n",
    "        else:\n",
    "            tgt += now\n",
    "        inc += 1\n",
    "    return tgt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pickle file containing ground truth data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pickle_data_give(filename):\n",
    "    '''Returns the attributes of the DCS pickle file\n",
    "    \n",
    "    Args:\n",
    "    filename (str) = name of file\n",
    "    \n",
    "    Returns:\n",
    "    output_load.sent_id (int): sentence id\n",
    "    output_load.sentence (str): sentence \n",
    "    output_load.dcs_chunks (list): chunks\n",
    "    output_load.lemmas (list): lemmas\n",
    "    output_load.cng (list): morphological class\n",
    "    \n",
    "    Raises:\n",
    "    '''\n",
    "    \n",
    "    output_load = pickle.load(open(filename, \"rb\"), encoding='utf-8')\n",
    "    \n",
    "    \n",
    "    return output_load.sent_id, output_load.sentence, output_load.dcs_chunks, output_load.lemmas, output_load.cng\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read graph ml file\n",
    "\n",
    "graph_file = nx.read_graphml(GRAPHML_FILE_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursively break and simplify a nested list\n",
    "\n",
    "def simplify_nested_list(nested_list):   \n",
    "    \n",
    "    # requires resetting of \"all_single_elements_list\" variable prior to each function call\n",
    "    \n",
    "    if len(nested_list) >= 1 and type(nested_list) is list:\n",
    "        for idx, ele in enumerate(nested_list):\n",
    "            #print(idx, ele, type(ele))\n",
    "            if type(ele) is str:\n",
    "                \n",
    "                all_single_elements_list.append([ele])\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                simplify_nested_list(nested_list[idx])\n",
    "                \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        all_single_elements_list.append(nested_list)\n",
    "        return (nested_list)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================\n",
      "\n",
      "\n",
      "lemmas:\t[['upās'], ['tapas'], ['niṣṭhā'], ['haṃsa'], ['mad'], ['muc'], ['kilbiṣa']] \n",
      "cngs:\t[['-19'], ['3'], ['39'], ['69'], ['72'], ['-190'], ['39']]\n",
      "\n",
      "\n",
      "******************************\n",
      "\n",
      "\n",
      "Current lemma: ['upās'] \tCurrent cng:['-19']\n",
      "checking node 6\n",
      "\t\tLemma:nizWA\tCng:80\n",
      "\n",
      "checking node 12\n",
      "\t\tLemma:nizWA\tCng:3\n",
      "\n",
      "checking node 11\n",
      "\t\tLemma:nizWa\tCng:40\n",
      "\n",
      "checking node 18\n",
      "\t\tLemma:mad\tCng:72\n",
      "\n",
      "checking node 15\n",
      "\t\tLemma:haMsa\tCng:69\n",
      "\n",
      "checking node 8\n",
      "\t\tLemma:nizWA\tCng:39\n",
      "\n",
      "checking node 17\n",
      "\t\tLemma:haMsa\tCng:31\n",
      "\n",
      "checking node 20\n",
      "\t\tLemma:muc\tCng:-190\n",
      "\n",
      "checking node 10\n",
      "\t\tLemma:nizWa\tCng:80\n",
      "\n",
      "checking node 1\n",
      "\t\tLemma:upAs\tCng:-19\n",
      "\n",
      "\t\t\t\t\t|$| - Here in node 1\n",
      "checking node 3\n",
      "\t\tLemma:tapas\tCng:71\n",
      "\n",
      "checking node 4\n",
      "\t\tLemma:tapas\tCng:31\n",
      "\n",
      "checking node 14\n",
      "\t\tLemma:nizWa\tCng:30\n",
      "\n",
      "checking node 19\n",
      "\t\tLemma:mukta\tCng:3\n",
      "\n",
      "checking node 23\n",
      "\t\tLemma:kilbiza\tCng:39\n",
      "\n",
      "checking node 16\n",
      "\t\tLemma:haMsa\tCng:71\n",
      "\n",
      "checking node 5\n",
      "\t\tLemma:tapa\tCng:29\n",
      "\n",
      "checking node 21\n",
      "\t\tLemma:kilbiza\tCng:80\n",
      "\n",
      "checking node 7\n",
      "\t\tLemma:nizWA\tCng:40\n",
      "\n",
      "checking node 2\n",
      "\t\tLemma:tapas\tCng:3\n",
      "\n",
      "checking node 13\n",
      "\t\tLemma:nizWA\tCng:30\n",
      "\n",
      "checking node 22\n",
      "\t\tLemma:kilbiza\tCng:40\n",
      "\n",
      "checking node 9\n",
      "\t\tLemma:nizWa\tCng:39\n",
      "\n",
      "\n",
      "\n",
      "******************************\n",
      "\n",
      "\n",
      "Current lemma: ['tapas'] \tCurrent cng:['3']\n",
      "checking node 6\n",
      "\t\tLemma:nizWA\tCng:80\n",
      "\n",
      "checking node 12\n",
      "\t\tLemma:nizWA\tCng:3\n",
      "\n",
      "checking node 11\n",
      "\t\tLemma:nizWa\tCng:40\n",
      "\n",
      "checking node 18\n",
      "\t\tLemma:mad\tCng:72\n",
      "\n",
      "checking node 15\n",
      "\t\tLemma:haMsa\tCng:69\n",
      "\n",
      "checking node 8\n",
      "\t\tLemma:nizWA\tCng:39\n",
      "\n",
      "checking node 17\n",
      "\t\tLemma:haMsa\tCng:31\n",
      "\n",
      "checking node 20\n",
      "\t\tLemma:muc\tCng:-190\n",
      "\n",
      "checking node 10\n",
      "\t\tLemma:nizWa\tCng:80\n",
      "\n",
      "checking node 1\n",
      "\t\tLemma:upAs\tCng:-19\n",
      "\n",
      "checking node 3\n",
      "\t\tLemma:tapas\tCng:71\n",
      "\n",
      "checking node 4\n",
      "\t\tLemma:tapas\tCng:31\n",
      "\n",
      "checking node 14\n",
      "\t\tLemma:nizWa\tCng:30\n",
      "\n",
      "checking node 19\n",
      "\t\tLemma:mukta\tCng:3\n",
      "\n",
      "checking node 23\n",
      "\t\tLemma:kilbiza\tCng:39\n",
      "\n",
      "checking node 16\n",
      "\t\tLemma:haMsa\tCng:71\n",
      "\n",
      "checking node 5\n",
      "\t\tLemma:tapa\tCng:29\n",
      "\n",
      "checking node 21\n",
      "\t\tLemma:kilbiza\tCng:80\n",
      "\n",
      "checking node 7\n",
      "\t\tLemma:nizWA\tCng:40\n",
      "\n",
      "checking node 2\n",
      "\t\tLemma:tapas\tCng:3\n",
      "\n",
      "\t\t\t\t\t|$| - Here in node 2\n",
      "checking node 13\n",
      "\t\tLemma:nizWA\tCng:30\n",
      "\n",
      "checking node 22\n",
      "\t\tLemma:kilbiza\tCng:40\n",
      "\n",
      "checking node 9\n",
      "\t\tLemma:nizWa\tCng:39\n",
      "\n",
      "\n",
      "\n",
      "******************************\n",
      "\n",
      "\n",
      "Current lemma: ['niṣṭhā'] \tCurrent cng:['39']\n",
      "checking node 6\n",
      "\t\tLemma:nizWA\tCng:80\n",
      "\n",
      "checking node 12\n",
      "\t\tLemma:nizWA\tCng:3\n",
      "\n",
      "checking node 11\n",
      "\t\tLemma:nizWa\tCng:40\n",
      "\n",
      "checking node 18\n",
      "\t\tLemma:mad\tCng:72\n",
      "\n",
      "checking node 15\n",
      "\t\tLemma:haMsa\tCng:69\n",
      "\n",
      "checking node 8\n",
      "\t\tLemma:nizWA\tCng:39\n",
      "\n",
      "\t\t\t\t\t|$| - Here in node 8\n",
      "checking node 17\n",
      "\t\tLemma:haMsa\tCng:31\n",
      "\n",
      "checking node 20\n",
      "\t\tLemma:muc\tCng:-190\n",
      "\n",
      "checking node 10\n",
      "\t\tLemma:nizWa\tCng:80\n",
      "\n",
      "checking node 1\n",
      "\t\tLemma:upAs\tCng:-19\n",
      "\n",
      "checking node 3\n",
      "\t\tLemma:tapas\tCng:71\n",
      "\n",
      "checking node 4\n",
      "\t\tLemma:tapas\tCng:31\n",
      "\n",
      "checking node 14\n",
      "\t\tLemma:nizWa\tCng:30\n",
      "\n",
      "checking node 19\n",
      "\t\tLemma:mukta\tCng:3\n",
      "\n",
      "checking node 23\n",
      "\t\tLemma:kilbiza\tCng:39\n",
      "\n",
      "checking node 16\n",
      "\t\tLemma:haMsa\tCng:71\n",
      "\n",
      "checking node 5\n",
      "\t\tLemma:tapa\tCng:29\n",
      "\n",
      "checking node 21\n",
      "\t\tLemma:kilbiza\tCng:80\n",
      "\n",
      "checking node 7\n",
      "\t\tLemma:nizWA\tCng:40\n",
      "\n",
      "checking node 2\n",
      "\t\tLemma:tapas\tCng:3\n",
      "\n",
      "checking node 13\n",
      "\t\tLemma:nizWA\tCng:30\n",
      "\n",
      "checking node 22\n",
      "\t\tLemma:kilbiza\tCng:40\n",
      "\n",
      "checking node 9\n",
      "\t\tLemma:nizWa\tCng:39\n",
      "\n",
      "\n",
      "\n",
      "******************************\n",
      "\n",
      "\n",
      "Current lemma: ['haṃsa'] \tCurrent cng:['69']\n",
      "checking node 6\n",
      "\t\tLemma:nizWA\tCng:80\n",
      "\n",
      "checking node 12\n",
      "\t\tLemma:nizWA\tCng:3\n",
      "\n",
      "checking node 11\n",
      "\t\tLemma:nizWa\tCng:40\n",
      "\n",
      "checking node 18\n",
      "\t\tLemma:mad\tCng:72\n",
      "\n",
      "checking node 15\n",
      "\t\tLemma:haMsa\tCng:69\n",
      "\n",
      "\t\t\t\t\t|$| - Here in node 15\n",
      "checking node 8\n",
      "\t\tLemma:nizWA\tCng:39\n",
      "\n",
      "checking node 17\n",
      "\t\tLemma:haMsa\tCng:31\n",
      "\n",
      "checking node 20\n",
      "\t\tLemma:muc\tCng:-190\n",
      "\n",
      "checking node 10\n",
      "\t\tLemma:nizWa\tCng:80\n",
      "\n",
      "checking node 1\n",
      "\t\tLemma:upAs\tCng:-19\n",
      "\n",
      "checking node 3\n",
      "\t\tLemma:tapas\tCng:71\n",
      "\n",
      "checking node 4\n",
      "\t\tLemma:tapas\tCng:31\n",
      "\n",
      "checking node 14\n",
      "\t\tLemma:nizWa\tCng:30\n",
      "\n",
      "checking node 19\n",
      "\t\tLemma:mukta\tCng:3\n",
      "\n",
      "checking node 23\n",
      "\t\tLemma:kilbiza\tCng:39\n",
      "\n",
      "checking node 16\n",
      "\t\tLemma:haMsa\tCng:71\n",
      "\n",
      "checking node 5\n",
      "\t\tLemma:tapa\tCng:29\n",
      "\n",
      "checking node 21\n",
      "\t\tLemma:kilbiza\tCng:80\n",
      "\n",
      "checking node 7\n",
      "\t\tLemma:nizWA\tCng:40\n",
      "\n",
      "checking node 2\n",
      "\t\tLemma:tapas\tCng:3\n",
      "\n",
      "checking node 13\n",
      "\t\tLemma:nizWA\tCng:30\n",
      "\n",
      "checking node 22\n",
      "\t\tLemma:kilbiza\tCng:40\n",
      "\n",
      "checking node 9\n",
      "\t\tLemma:nizWa\tCng:39\n",
      "\n",
      "\n",
      "\n",
      "******************************\n",
      "\n",
      "\n",
      "Current lemma: ['mad'] \tCurrent cng:['72']\n",
      "checking node 6\n",
      "\t\tLemma:nizWA\tCng:80\n",
      "\n",
      "checking node 12\n",
      "\t\tLemma:nizWA\tCng:3\n",
      "\n",
      "checking node 11\n",
      "\t\tLemma:nizWa\tCng:40\n",
      "\n",
      "checking node 18\n",
      "\t\tLemma:mad\tCng:72\n",
      "\n",
      "\t\t\t\t\t|$| - Here in node 18\n",
      "checking node 15\n",
      "\t\tLemma:haMsa\tCng:69\n",
      "\n",
      "checking node 8\n",
      "\t\tLemma:nizWA\tCng:39\n",
      "\n",
      "checking node 17\n",
      "\t\tLemma:haMsa\tCng:31\n",
      "\n",
      "checking node 20\n",
      "\t\tLemma:muc\tCng:-190\n",
      "\n",
      "checking node 10\n",
      "\t\tLemma:nizWa\tCng:80\n",
      "\n",
      "checking node 1\n",
      "\t\tLemma:upAs\tCng:-19\n",
      "\n",
      "checking node 3\n",
      "\t\tLemma:tapas\tCng:71\n",
      "\n",
      "checking node 4\n",
      "\t\tLemma:tapas\tCng:31\n",
      "\n",
      "checking node 14\n",
      "\t\tLemma:nizWa\tCng:30\n",
      "\n",
      "checking node 19\n",
      "\t\tLemma:mukta\tCng:3\n",
      "\n",
      "checking node 23\n",
      "\t\tLemma:kilbiza\tCng:39\n",
      "\n",
      "checking node 16\n",
      "\t\tLemma:haMsa\tCng:71\n",
      "\n",
      "checking node 5\n",
      "\t\tLemma:tapa\tCng:29\n",
      "\n",
      "checking node 21\n",
      "\t\tLemma:kilbiza\tCng:80\n",
      "\n",
      "checking node 7\n",
      "\t\tLemma:nizWA\tCng:40\n",
      "\n",
      "checking node 2\n",
      "\t\tLemma:tapas\tCng:3\n",
      "\n",
      "checking node 13\n",
      "\t\tLemma:nizWA\tCng:30\n",
      "\n",
      "checking node 22\n",
      "\t\tLemma:kilbiza\tCng:40\n",
      "\n",
      "checking node 9\n",
      "\t\tLemma:nizWa\tCng:39\n",
      "\n",
      "\n",
      "\n",
      "******************************\n",
      "\n",
      "\n",
      "Current lemma: ['muc'] \tCurrent cng:['-190']\n",
      "checking node 6\n",
      "\t\tLemma:nizWA\tCng:80\n",
      "\n",
      "checking node 12\n",
      "\t\tLemma:nizWA\tCng:3\n",
      "\n",
      "checking node 11\n",
      "\t\tLemma:nizWa\tCng:40\n",
      "\n",
      "checking node 18\n",
      "\t\tLemma:mad\tCng:72\n",
      "\n",
      "checking node 15\n",
      "\t\tLemma:haMsa\tCng:69\n",
      "\n",
      "checking node 8\n",
      "\t\tLemma:nizWA\tCng:39\n",
      "\n",
      "checking node 17\n",
      "\t\tLemma:haMsa\tCng:31\n",
      "\n",
      "checking node 20\n",
      "\t\tLemma:muc\tCng:-190\n",
      "\n",
      "\t\t\t\t\t|$| - Here in node 20\n",
      "checking node 10\n",
      "\t\tLemma:nizWa\tCng:80\n",
      "\n",
      "checking node 1\n",
      "\t\tLemma:upAs\tCng:-19\n",
      "\n",
      "checking node 3\n",
      "\t\tLemma:tapas\tCng:71\n",
      "\n",
      "checking node 4\n",
      "\t\tLemma:tapas\tCng:31\n",
      "\n",
      "checking node 14\n",
      "\t\tLemma:nizWa\tCng:30\n",
      "\n",
      "checking node 19\n",
      "\t\tLemma:mukta\tCng:3\n",
      "\n",
      "checking node 23\n",
      "\t\tLemma:kilbiza\tCng:39\n",
      "\n",
      "checking node 16\n",
      "\t\tLemma:haMsa\tCng:71\n",
      "\n",
      "checking node 5\n",
      "\t\tLemma:tapa\tCng:29\n",
      "\n",
      "checking node 21\n",
      "\t\tLemma:kilbiza\tCng:80\n",
      "\n",
      "checking node 7\n",
      "\t\tLemma:nizWA\tCng:40\n",
      "\n",
      "checking node 2\n",
      "\t\tLemma:tapas\tCng:3\n",
      "\n",
      "checking node 13\n",
      "\t\tLemma:nizWA\tCng:30\n",
      "\n",
      "checking node 22\n",
      "\t\tLemma:kilbiza\tCng:40\n",
      "\n",
      "checking node 9\n",
      "\t\tLemma:nizWa\tCng:39\n",
      "\n",
      "\n",
      "\n",
      "******************************\n",
      "\n",
      "\n",
      "Current lemma: ['kilbiṣa'] \tCurrent cng:['39']\n",
      "checking node 6\n",
      "\t\tLemma:nizWA\tCng:80\n",
      "\n",
      "checking node 12\n",
      "\t\tLemma:nizWA\tCng:3\n",
      "\n",
      "checking node 11\n",
      "\t\tLemma:nizWa\tCng:40\n",
      "\n",
      "checking node 18\n",
      "\t\tLemma:mad\tCng:72\n",
      "\n",
      "checking node 15\n",
      "\t\tLemma:haMsa\tCng:69\n",
      "\n",
      "checking node 8\n",
      "\t\tLemma:nizWA\tCng:39\n",
      "\n",
      "checking node 17\n",
      "\t\tLemma:haMsa\tCng:31\n",
      "\n",
      "checking node 20\n",
      "\t\tLemma:muc\tCng:-190\n",
      "\n",
      "checking node 10\n",
      "\t\tLemma:nizWa\tCng:80\n",
      "\n",
      "checking node 1\n",
      "\t\tLemma:upAs\tCng:-19\n",
      "\n",
      "checking node 3\n",
      "\t\tLemma:tapas\tCng:71\n",
      "\n",
      "checking node 4\n",
      "\t\tLemma:tapas\tCng:31\n",
      "\n",
      "checking node 14\n",
      "\t\tLemma:nizWa\tCng:30\n",
      "\n",
      "checking node 19\n",
      "\t\tLemma:mukta\tCng:3\n",
      "\n",
      "checking node 23\n",
      "\t\tLemma:kilbiza\tCng:39\n",
      "\n",
      "\t\t\t\t\t|$| - Here in node 23\n",
      "checking node 16\n",
      "\t\tLemma:haMsa\tCng:71\n",
      "\n",
      "checking node 5\n",
      "\t\tLemma:tapa\tCng:29\n",
      "\n",
      "checking node 21\n",
      "\t\tLemma:kilbiza\tCng:80\n",
      "\n",
      "checking node 7\n",
      "\t\tLemma:nizWA\tCng:40\n",
      "\n",
      "checking node 2\n",
      "\t\tLemma:tapas\tCng:3\n",
      "\n",
      "checking node 13\n",
      "\t\tLemma:nizWA\tCng:30\n",
      "\n",
      "checking node 22\n",
      "\t\tLemma:kilbiza\tCng:40\n",
      "\n",
      "checking node 9\n",
      "\t\tLemma:nizWa\tCng:39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# algorithm to find the cng+lemma combinations\n",
    "\n",
    "_, dcs_sentence, _, lemmas, cng = pickle_data_give(PICKLE_DCS_FILE_NAME)\n",
    "#print(lemma, '\\n',cng)\n",
    "\n",
    "#print(len(dcs_sentence.strip().rstrip().split(' ')))\n",
    "#print(dcs_sentence.strip().rstrip().split(' '))\n",
    "graph_ground_truth_ids = []\n",
    "flattened_chunk_no = []\n",
    "print('==========================================================================')\n",
    "\n",
    "\n",
    "#get chunk no's flattened list\n",
    "for idx, lemma in enumerate(lemmas):\n",
    "    #print(len(lemma))\n",
    "    if len(lemma)>1:\n",
    "        #print('$')\n",
    "        tmp=[]\n",
    "        for x in range(len(lemma)):\n",
    "            tmp.append(str(idx+1))\n",
    "        flattened_chunk_no.append(tmp)\n",
    "    else:\n",
    "        #print('%')\n",
    "        flattened_chunk_no.append(str(idx+1))\n",
    "        \n",
    "\n",
    "all_single_elements_list = []\n",
    "simplify_nested_list(flattened_chunk_no)\n",
    "flattened_chunk_no = all_single_elements_list \n",
    "        \n",
    "        \n",
    "all_single_elements_list = []\n",
    "simplify_nested_list(lemmas)\n",
    "lemmas = all_single_elements_list\n",
    "\n",
    "\n",
    "all_single_elements_list = []\n",
    "simplify_nested_list(cng)\n",
    "cng = all_single_elements_list\n",
    "\n",
    "print('\\n\\nlemmas:\\t%s \\ncngs:\\t%s' %(lemmas, cng))\n",
    "\n",
    "lemma_cng = zip(lemmas, cng)\n",
    "\n",
    "number_of_chunks = len(dcs_sentence.strip().rstrip().split(' '))\n",
    "\n",
    "\n",
    "for dcs_lemma, dcs_cng in lemma_cng:\n",
    "    print('\\n\\n******************************')\n",
    "    print('\\n\\nCurrent lemma: %s \\tCurrent cng:%s' %(dcs_lemma, dcs_cng))\n",
    "    \n",
    "    same_ground_truth_ids = []\n",
    "    \n",
    "    for di in graph_file.nodes():\n",
    "        \n",
    "        graph_file.add_node(str(di), ground_truth_id=0)\n",
    "        \n",
    "        # this is random one time traversal search in the whole graph\n",
    "        #print('Current node:%s' %(di))\n",
    "        temp_dict = graph_file.nodes[di]\n",
    "        \n",
    "        # convert the lemma to slp1\n",
    "        dcs_lemma[0] = iast2slp(dcs_lemma[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('checking node %s' %(di))\n",
    "        print('\\t\\tLemma:%s\\tCng:%s\\n' %(temp_dict['lemma'], temp_dict['cng']))\n",
    "        \n",
    "        # check if in the current node, the cng matches to the pickle file cng\n",
    "        if temp_dict['cng'] == int(dcs_cng[0]):\n",
    "                       \n",
    "            \n",
    "            \n",
    "            # check if in the current node, the lemma matches to the pickle file lemma\n",
    "            if (temp_dict['lemma'] == dcs_lemma[0]):\n",
    "                \n",
    "                # only if cng and the converted lemma match, then these are executed\n",
    "                \n",
    "                #if tempdict chunk number matches dcs chnk number\n",
    "                print('\\t\\t\\t\\t\\t|$| - Here in node %s' %(di))\n",
    "                #graph_file.add_node(di, ground_truth_id=1)\n",
    "                same_ground_truth_ids.append(di)\n",
    "        else:\n",
    "            \n",
    "            graph_file.add_node(str(di), ground_truth_id=0)\n",
    "        \n",
    "    graph_ground_truth_ids.append(same_ground_truth_ids)\n",
    "                \n",
    "                #print('#', di, '\\n')\n",
    "    \n",
    "\n",
    "#return len(graph_ground_truth_ids)/number_of_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to pick one cng+lemma combination if redundant units are present.\n",
    "\n",
    "def pick_one_cng_lemma(graph_ground_truth_ids):\n",
    "    \n",
    "    update_ground_truth_ids = []\n",
    "    graph_ground_truth_ids = list(filter(None, graph_ground_truth_ids))\n",
    "    for ids_list in graph_ground_truth_ids:\n",
    "        if len(ids_list) > 1:\n",
    "            chose_cng_lemma = random.choice(ids_list)\n",
    "            graph_file.add_node(chose_cng_lemma, ground_truth_id=1)\n",
    "        else:\n",
    "            chose_cng_lemma = ids_list[0]            \n",
    "            graph_file.add_node(chose_cng_lemma, ground_truth_id=1)\n",
    "            \n",
    "        update_ground_truth_ids.append(chose_cng_lemma)\n",
    "    \n",
    "    return update_ground_truth_ids\n",
    "    \n",
    "graph_ground_truth_ids = pick_one_cng_lemma(graph_ground_truth_ids)\n",
    "#print(graph_ground_truth_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the set of ground truth id's form a complete graph or not\n",
    "\n",
    "\n",
    "        \n",
    "def check_complete_graph(graph_file, graph_ground_truth_ids):\n",
    "    graph_status = False\n",
    "     \n",
    "    #print(graph_file.get_edge_data(graph_ground_truth_ids[0], graph_ground_truth_ids[1])['key'])\n",
    "    for idx in range(1, len(graph_ground_truth_ids)):\n",
    "               \n",
    "        try :\n",
    "            if graph_file.get_edge_data(graph_ground_truth_ids[idx-1], graph_ground_truth_ids[idx])['key'] == 2:\n",
    "                print('conflicting edge!!  \\t\\t\\t', graph_file.has_edge(graph_ground_truth_ids[idx-1], graph_ground_truth_ids[idx]))\n",
    "                graph_status = False\n",
    "                break\n",
    "            if graph_file.get_edge_data(graph_ground_truth_ids[idx-1], graph_ground_truth_ids[idx])['key'] == 1:\n",
    "                print('not a conflicting edge \\t\\t\\t', graph_file.has_edge(graph_ground_truth_ids[idx-1], graph_ground_truth_ids[idx]))\n",
    "                print(graph_file.nodes[graph_ground_truth_ids[idx-1]]['word'], graph_file.nodes[graph_ground_truth_ids[idx]]['word'])\n",
    "                print(graph_ground_truth_ids[idx-1], graph_ground_truth_ids[idx])\n",
    "                print('\\n')\n",
    "                graph_status = True\n",
    "        except KeyError and TypeError as key_type_issue:\n",
    "            print(key_type_issue)\n",
    "        \n",
    "    return graph_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The ground truth ids are given below and we check if they have a non conflicting edge or not between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '8', '15', '18', '20', '23']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#graph ground truth ids\n",
    "\n",
    "graph_ground_truth_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below line is used to check if the nodes have edge between them or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#graph_file.has_edge('83', '86')\n",
    "# uncomment the lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below line is used to check if they confict or not\n",
    "\n",
    "if 2 is returned then it's a conflicting edge\n",
    "\n",
    "if 1 is returned then it's a not a conflicting edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph_file.get_edge_data('1', '12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Graph ground truth nodes:\n",
      "['1', '2', '8', '15', '18', '20', '23']\n",
      "upAsate tapaH nizWAH haMsam mAm mukta kilbizAH \n",
      "\n",
      "\n",
      "DCS sentence below:\n",
      "\n",
      "sentence id: \t29088\n",
      "sentence : \tupAsate taponizWA haMsaM mAM muktakilbizAH    \n",
      "chunks: \t['upās', 'tapas', 'niṣṭhā', 'haṃsa', 'mad', 'muc', 'kilbiṣa']\n",
      "lemmas: \t[['upās'], ['tapas', 'niṣṭhā'], ['haṃsa'], ['mad'], ['muc', 'kilbiṣa']]\n",
      "morph class: \t[['-19'], ['3', '39'], ['69'], ['72'], ['-190', '39']]\n",
      "\n",
      "\n",
      "\n",
      "========================\n",
      "not a conflicting edge \t\t\t True\n",
      "upAsate tapaH\n",
      "1 2\n",
      "\n",
      "\n",
      "conflicting edge!!  \t\t\t True\n",
      "\n",
      "\n",
      "\n",
      "Graph status:  False\n"
     ]
    }
   ],
   "source": [
    "# snippet to get the ground truth sentence from the graphML file\n",
    "\n",
    "print('\\n\\nGraph ground truth nodes:')\n",
    "#graph_ground_truth_ids = sorted(graph_ground_truth_ids, key = lambda x : graph_file.nodes[x]['chunk_no'])\n",
    "print(graph_ground_truth_ids)\n",
    "\n",
    "\n",
    "for ids in graph_ground_truth_ids:\n",
    "    ids = str(ids)\n",
    "    print(graph_file.nodes[str(ids)]['word'], end=' ')\n",
    "\n",
    "  \n",
    "print('\\n\\n')\n",
    "print('DCS sentence below:\\n')\n",
    "\n",
    "for idx, _ in enumerate(pickle_data_give(PICKLE_DCS_FILE_NAME)):\n",
    "    print('%s: \\t%s' %(dcs_class_params[idx], _))\n",
    "    \n",
    "print('\\n\\n\\n========================')\n",
    "graph_complete_or_not = check_complete_graph(graph_file, graph_ground_truth_ids)\n",
    "print('\\n\\n\\nGraph status: ',graph_complete_or_not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible solutions from here\n",
    "\n",
    "In such a case where we have a conflicting edge between ground truth nodes.\n",
    "\n",
    "- either leave them as it is and update the ground truths. ( no overwriting of previous attributes)\n",
    "\n",
    "- or overwrite \n",
    "    - the previous attributes and create non coflicting edges incase conflicting.\n",
    "    \n",
    "Again would prefer the overwrite option because\n",
    " - the ground truth ids give correct solution\n",
    " - correct features for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
